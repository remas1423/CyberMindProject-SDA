{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell A: install python packages\n",
        "!pip install -q streamlit reportlab pandas matplotlib\n",
        "# optional: reduce log spam"
      ],
      "metadata": {
        "id": "emeZ2SzeimjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d56913d-5c12-4b6d-8175-ea1e158f7b82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "L8B49QX2pDnO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "RMfuY-BXvLi8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B: save a minimal Streamlit app (replace later with your full app)\n",
        "app_code = r\"\"\"\n",
        "import streamlit as st\n",
        "st.set_page_config(page_title=\"CyberMind\", layout=\"wide\")\n",
        "st.title(\"CyberMind Dashboard (test)\")\n",
        "st.write(\"If you see this, Streamlit is running.\")\n",
        "\"\"\"\n",
        "with open(\"app.py\",\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(app_code)\n",
        "print(\"Saved app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPLaUeFbi5Lu",
        "outputId": "2b29bc30-169e-4403-e5ce-8f0a0e0cb214"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell I: Final corrected and enhanced app.py (PDF filter, PDF table fix, Mitigation enforcement)\n",
        "\n",
        "%%writefile app.py\n",
        "# app.py â€” CyberMind Streamlit Dashboard (Final)\n",
        "\n",
        "import io, json, re\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Page setup â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "st.set_page_config(page_title=\"CyberMind Dashboard\", page_icon=\"ğŸ›¡\", layout=\"wide\")\n",
        "PRIMARY = \"#0B5ED7\"; ACCENT = \"#22B07D\"; MUTED = \"#6c757d\"\n",
        "st.markdown(f\"\"\"\n",
        "<style>\n",
        ".cm-badge {{display:inline-block;padding:4px 10px;border-radius:999px;background:{ACCENT}15;color:{ACCENT};\n",
        "            font-weight:600;font-size:12px;border:1px solid {ACCENT}55;}}\n",
        ".cm-card {{border:1px solid #e9ecef;padding:16px;border-radius:12px;background:white;}}\n",
        ".cm-h1 {{font-size:28px;font-weight:800;color:{PRIMARY};margin-bottom:0}}\n",
        ".cm-sub {{color:{MUTED};font-size:13px}}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Demo data â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "DEMO_DATA = [\n",
        "    {\n",
        "        \"cve_id\": \"CVE-2025-59248\",\n",
        "        \"title\": \"Microsoft Exchange Server â€“ spoofing & auth issues\",\n",
        "        \"description\": \"Multiple high-severity issues in Exchange may enable spoofing and privilege escalation.\",\n",
        "        \"cvss_v3\": \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:L\",\n",
        "        \"priority\": \"Critical\", # Changed to Critical for demo purposes\n",
        "        \"effort\": \"Medium\",\n",
        "        \"mitigations\": [\n",
        "            \"Apply latest Microsoft security updates.\",\n",
        "            \"Enforce strong authentication & input validation.\",\n",
        "            \"Audit logs for suspicious auth flows.\"\n",
        "        ],\n",
        "        \"references\": [\"https://msrc.microsoft.com/update-guide/\"],\n",
        "        \"source\": \"Demo\"\n",
        "    },\n",
        "    {\n",
        "        \"cve_id\": \"CVE-2025-53782\",\n",
        "        \"title\": \"SQL Injection in Product X\",\n",
        "        \"description\": \"Insufficient sanitization allows SQL injection in login workflow.\",\n",
        "        \"cvss_v3\": \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\",\n",
        "        \"priority\": \"High\",\n",
        "        \"effort\": \"Medium\",\n",
        "        \"mitigations\": [\n",
        "            \"Use parameterized queries / prepared statements.\",\n",
        "            \"Centralize input validation.\",\n",
        "            \"WAF rules for SQLi signatures.\"\n",
        "        ],\n",
        "        \"references\": [\"https://owasp.org/www-community/attacks/SQL_Injection\"],\n",
        "        \"source\": \"Demo\"\n",
        "    },\n",
        "    {\n",
        "        \"cve_id\": \"CVE-2025-55999\",\n",
        "        \"title\": \"Outdated 3rd-party library in backend\",\n",
        "        \"description\": \"Known vulnerable dependency may lead to RCE under certain configs.\",\n",
        "        \"cvss_v3\": \"CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H\",\n",
        "        \"priority\": \"Medium\",\n",
        "        \"effort\": \"Low\",\n",
        "        \"mitigations\": [\n",
        "            \"Upgrade dependency to a patched version.\",\n",
        "            \"Pin versions and enable Dependabot.\",\n",
        "            \"SBOM + regular SCA scans.\"\n",
        "        ],\n",
        "        \"references\": [\"https://nvd.nist.gov/\"],\n",
        "        \"source\": \"Demo\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers (upgraded) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def ensure_list(x):\n",
        "    if x is None: return []\n",
        "    if isinstance(x, list): return x\n",
        "    return [x]\n",
        "\n",
        "def _try_float(x):\n",
        "    try: return float(x)\n",
        "    except: return None\n",
        "\n",
        "def extract_cvss_score(it: dict) -> float|None:\n",
        "    # direct numeric\n",
        "    for k in [\"cvss_score\",\"cvssScore\",\"baseScore\"]:\n",
        "        if k in it:\n",
        "            s = _try_float(it[k])\n",
        "            if s is not None: return s\n",
        "    # vector-like strings\n",
        "    for k in [\"cvss_v3\",\"cvss\",\"cvssVector\"]:\n",
        "        v = it.get(k)\n",
        "        if isinstance(v, str):\n",
        "            m = re.search(r\"(\\d+\\.\\d+)\", v)\n",
        "            if m: return _try_float(m.group(1))\n",
        "    # severity arrays\n",
        "    sev = it.get(\"severity\")\n",
        "    if isinstance(sev, list):\n",
        "        for s in sev:\n",
        "            if isinstance(s, dict):\n",
        "                for kk in [\"score\",\"baseScore\",\"value\"]:\n",
        "                    sc = _try_float(s.get(kk))\n",
        "                    if sc is not None: return sc\n",
        "                txt = \" \".join([str(x) for x in s.values() if isinstance(x, str)])\n",
        "                m = re.search(r\"(\\d+\\.\\d+)\", txt)\n",
        "                if m: return _try_float(m.group(1))\n",
        "    # NVD metrics trees\n",
        "    metrics = it.get(\"metrics\") or {}\n",
        "    if isinstance(metrics, dict):\n",
        "        for key in [\"cvssMetricV31\",\"cvssMetricV30\",\"cvssMetricV2\"]:\n",
        "            arr = metrics.get(key)\n",
        "            if isinstance(arr, list) and arr:\n",
        "                data = arr[0].get(\"cvssData\") if isinstance(arr[0], dict) else None\n",
        "                if isinstance(data, dict) and \"baseScore\" in data:\n",
        "                    sc = _try_float(data[\"baseScore\"])\n",
        "                    if sc is not None: return sc\n",
        "    # fallback: scan any string\n",
        "    for v in it.values():\n",
        "        if isinstance(v, str):\n",
        "            m = re.search(r\"(\\d+\\.\\d+)\", v)\n",
        "            if m: return _try_float(m.group(1))\n",
        "    return None\n",
        "\n",
        "def priority_from_cvss(score: float|None) -> str:\n",
        "    if score is None: return \"Unknown\"\n",
        "    if score >= 9.0:  return \"Critical\"\n",
        "    if score >= 7.0:  return \"High\"\n",
        "    if score >= 4.0:  return \"Medium\"\n",
        "    if score >  0.0:  return \"Low\"\n",
        "    return \"Unknown\"\n",
        "\n",
        "MITIGATION_RULES = [\n",
        "    (r\"sql\\s*injection|sqli\", [\n",
        "        \"Use parameterized queries / prepared statements.\",\n",
        "        \"Centralize input validation & encoding.\",\n",
        "        \"Enable WAF rules for SQLi signatures.\"\n",
        "    ]),\n",
        "    (r\"\\bxss\\b|cross[-\\s]?site\", [\n",
        "        \"Encode untrusted data in HTML/JS contexts.\",\n",
        "        \"Use Content-Security-Policy (CSP).\",\n",
        "        \"Sanitize and validate all inputs.\"\n",
        "    ]),\n",
        "    (r\"\\brce\\b|remote code\", [\n",
        "        \"Patch vulnerable components immediately.\",\n",
        "        \"Run services with least privilege.\",\n",
        "        \"Restrict egress and monitor exec calls.\"\n",
        "    ]),\n",
        "    (r\"authentica|authorization|privilege\", [\n",
        "        \"Enforce MFA and strong authentication.\",\n",
        "        \"Harden session management and token TTL.\",\n",
        "        \"Apply least-privilege on roles.\"\n",
        "    ]),\n",
        "]\n",
        "\n",
        "def suggest_mitigations(text: str) -> list[str]:\n",
        "    text = (text or \"\").lower()\n",
        "    out = []\n",
        "    for pat, tips in MITIGATION_RULES:\n",
        "        if re.search(pat, text):\n",
        "            out.extend(tips)\n",
        "    # unique + cap length\n",
        "    return list(dict.fromkeys(out))[:6]\n",
        "\n",
        "def normalize_records(raw):\n",
        "    \"\"\"Normalize list[dict] to DataFrame with unified columns.\"\"\"\n",
        "    rows = []\n",
        "    for it in raw:\n",
        "        try:\n",
        "            cve_id = it.get(\"cve_id\") or it.get(\"id\") or it.get(\"CVE\") or it.get(\"cveId\") or \"\"\n",
        "            title  = it.get(\"title\") or it.get(\"summary\") or it.get(\"name\") or \"\"\n",
        "            desc   = it.get(\"description\") or it.get(\"details\") or it.get(\"desc\") or \"\"\n",
        "\n",
        "            # NVD CVE 5.x (containers.cna)\n",
        "            if not (title or desc):\n",
        "                cna = (it.get(\"containers\") or {}).get(\"cna\") or {}\n",
        "                if not title:\n",
        "                    title = cna.get(\"title\") or \"\"\n",
        "                if not desc:\n",
        "                    for d in ensure_list(cna.get(\"descriptions\")):\n",
        "                        if isinstance(d, dict) and d.get(\"lang\") == \"en\":\n",
        "                            desc = d.get(\"value\") or desc\n",
        "\n",
        "            cvss_vec = it.get(\"cvss_v3\") or it.get(\"cvss\") or \"\"\n",
        "            cvss_num = extract_cvss_score(it)\n",
        "\n",
        "            prio = (it.get(\"priority\") or \"\").title()\n",
        "            if not prio or prio == \"Unknown\":\n",
        "                prio = priority_from_cvss(cvss_num)\n",
        "\n",
        "            mit = ensure_list(it.get(\"mitigations\") or it.get(\"MitigationSteps\"))\n",
        "            # Hardcoded rules are applied here during normalization\n",
        "            if not mit:\n",
        "                mit = suggest_mitigations(f\"{title} {desc}\")\n",
        "\n",
        "            refs = ensure_list(it.get(\"references\"))\n",
        "\n",
        "            effort = (it.get(\"effort\") or \"Unknown\").title()\n",
        "            source = it.get(\"source\") or \"Uploaded\"\n",
        "\n",
        "            rows.append({\n",
        "                \"cve_id\": cve_id,\n",
        "                \"title\": title,\n",
        "                \"description\": desc,\n",
        "                \"cvss_v3\": cvss_vec,\n",
        "                \"priority\": prio,\n",
        "                \"effort\": effort,\n",
        "                \"mitigations\": \", \".join(mit) if mit else \"\",\n",
        "                \"references\": \", \".join(refs) if refs else \"\",\n",
        "                \"source\": source,\n",
        "                \"cvss_numeric\": cvss_num\n",
        "            })\n",
        "        except Exception:\n",
        "            continue\n",
        "    df = pd.DataFrame(rows)\n",
        "    if len(df) == 0:\n",
        "        return pd.DataFrame(columns=[\"cve_id\",\"title\",\"description\",\"cvss_v3\",\"priority\",\"effort\",\"mitigations\",\"references\",\"source\",\"cvss_numeric\"])\n",
        "    return df\n",
        "\n",
        "def load_any_file(uploaded):\n",
        "    name = uploaded.name.lower()\n",
        "    if name.endswith(\".json\"):\n",
        "        data = json.load(uploaded)\n",
        "        if isinstance(data, dict):\n",
        "            if \"items\" in data and isinstance(data[\"items\"], list):\n",
        "                return data[\"items\"]\n",
        "            return [data]\n",
        "        return data\n",
        "    elif name.endswith(\".csv\"):\n",
        "        df = pd.read_csv(uploaded)\n",
        "        return df.to_dict(orient=\"records\")\n",
        "    else:\n",
        "        st.warning(\"Please upload JSON or CSV.\")\n",
        "        return []\n",
        "\n",
        "def kpi_card(label, value, help_txt=None):\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <div class=\"cm-card\">\n",
        "          <div class=\"cm-sub\">{label}</div>\n",
        "          <div style=\"font-size:26px;font-weight:800;margin-top:2px\">{value}</div>\n",
        "          {f'<div class=\"cm-sub\" style=\"margin-top:4px\">{help_txt}</div>' if help_txt else ''}\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "def filter_dataframe(df, query, severities):\n",
        "    out = df.copy()\n",
        "    if query:\n",
        "        q = query.lower().strip()\n",
        "        mask = (\n",
        "            out[\"cve_id\"].str.lower().str.contains(q, na=False) |\n",
        "            out[\"title\"].str.lower().str.contains(q, na=False) |\n",
        "            out[\"description\"].str.lower().str.contains(q, na=False)\n",
        "        )\n",
        "        out = out[mask]\n",
        "    if severities and \"All\" not in severities:\n",
        "        out = out[out[\"priority\"].isin(severities)]\n",
        "    return out\n",
        "\n",
        "# ğŸ’¡ ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© ØªØ¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ø§Ø³ØªØ®Ø¯Ø§Ù… Paragraph Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ø¯ÙˆÙ„)\n",
        "def make_pdf(df_in, filter_prio=None):\n",
        "    \"\"\"Generate in-memory PDF using reportlab (patched: wrapping + NVD-safe).\"\"\"\n",
        "\n",
        "    # 1. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„ØªÙ‚Ø±ÙŠØ±\n",
        "    df = df_in.copy()\n",
        "    if filter_prio and filter_prio != \"All\":\n",
        "        df = df[df[\"priority\"] == filter_prio]\n",
        "\n",
        "    if df.empty:\n",
        "        st.error(f\"No records found for priority: {filter_prio}\")\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        from reportlab.platypus import (\n",
        "            SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle,\n",
        "            PageBreak, ListFlowable, ListItem\n",
        "        )\n",
        "        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "        from reportlab.lib import colors\n",
        "        from reportlab.lib.pagesizes import A4\n",
        "        from reportlab.lib.units import inch\n",
        "    except Exception:\n",
        "        st.error(\"ReportLab is not installed on this environment.\")\n",
        "        return None, None\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "\n",
        "    doc = SimpleDocTemplate(\n",
        "        buf,\n",
        "        pagesize=A4,\n",
        "        leftMargin=40,\n",
        "        rightMargin=40,\n",
        "        topMargin=50,\n",
        "        bottomMargin=40,\n",
        "    )\n",
        "\n",
        "    styles = getSampleStyleSheet()\n",
        "    Title = styles[\"Title\"]\n",
        "    Title.fontSize = 22\n",
        "\n",
        "    H2 = styles[\"Heading2\"]\n",
        "    H2.fontSize = 14\n",
        "\n",
        "    Normal = styles[\"Normal\"]\n",
        "\n",
        "    # âœ” Wrapped style: prevents overlapping - Ù…Ù‡Ù… Ù„Ù„ÙˆØµÙ ÙˆØ§Ù„Ø­Ù„ÙˆÙ„\n",
        "    Wrapped = ParagraphStyle(\n",
        "        \"Wrapped\",\n",
        "        parent=Normal,\n",
        "        fontSize=9,\n",
        "        leading=11,\n",
        "        wordWrap=\"CJK\",\n",
        "    )\n",
        "\n",
        "    # ØªÙ†Ø³ÙŠÙ‚ Ø®Ø§Øµ Ù„Ù„Ø­Ù„ÙˆÙ„ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„)\n",
        "    TableWrapped = ParagraphStyle(\n",
        "        \"TableWrapped\",\n",
        "        parent=Normal,\n",
        "        fontSize=8,\n",
        "        leading=10,\n",
        "        wordWrap=\"CJK\",\n",
        "    )\n",
        "\n",
        "\n",
        "    story = []\n",
        "\n",
        "    # â–‘â–‘â–‘ HEADER â–‘â–‘â–‘\n",
        "    report_title = f\"CyberMind â€” Consolidated Security Report ({filter_prio or 'All'} Findings)\"\n",
        "    story.append(Paragraph(report_title, Title))\n",
        "    ts = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "    story.append(Paragraph(f\"Generated: {ts}\", Normal))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # â–‘â–‘â–‘ EXEC SUMMARY â–‘â–‘â–‘\n",
        "    total = len(df)\n",
        "    critical = int((df[\"priority\"] == \"Critical\").sum()) if \"priority\" in df else 0\n",
        "\n",
        "    story.append(Paragraph(\"Executive Summary\", H2))\n",
        "    story.append(Paragraph(\n",
        "        f\"Total findings in report: <b>{total}</b> &nbsp;&nbsp;|&nbsp;&nbsp; Critical: <b>{critical}</b>\",\n",
        "        Normal,\n",
        "    ))\n",
        "    story.append(Spacer(1, 10))\n",
        "\n",
        "    # â–‘â–‘â–‘ TABLE (Wrapped, fixed column widths, using Paragraphs for wrapping) â–‘â–‘â–‘\n",
        "    cols = [\"cve_id\", \"priority\", \"cvss_v3\", \"mitigations\"]\n",
        "    rows = [\n",
        "        [\n",
        "            Paragraph(\"CVE\", Normal),\n",
        "            Paragraph(\"Priority\", Normal),\n",
        "            Paragraph(\"CVSS\", Normal),\n",
        "            Paragraph(\"Key Mitigations\", Normal)\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 15 Ø³Ø¬Ù„ ÙÙŠ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ\n",
        "    for _, r in df.head(15).iterrows():\n",
        "        cvss = r.get(\"cvss_v3\", \"â€”\")\n",
        "\n",
        "        mit_raw = r.get(\"mitigations\", \"\") or \"\"\n",
        "        if mit_raw.lower() in [\"none\", \"nan\"] or not mit_raw:\n",
        "            mit_raw = \"â€”\"\n",
        "\n",
        "        mit_text = mit_raw[:150] # Ù‚Øµ Ø§Ù„Ù†Øµ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„Ù„Ø¬Ø¯ÙˆÙ„\n",
        "\n",
        "        rows.append([\n",
        "            Paragraph(r.get(\"cve_id\", \"â€”\"), TableWrapped),\n",
        "            Paragraph(r.get(\"priority\", \"Unknown\"), TableWrapped),\n",
        "            Paragraph(cvss, TableWrapped),\n",
        "            # ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… TableWrapped Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙØ§Ù Ø§Ù„Ù†Øµ ÙÙŠ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø­Ù„ÙˆÙ„\n",
        "            Paragraph(mit_text, TableWrapped),\n",
        "        ])\n",
        "\n",
        "    tbl = Table(\n",
        "        rows,\n",
        "        repeatRows=1,\n",
        "        # ğŸ’¡ Ø²ÙŠØ§Ø¯Ø© Ø¹Ø±Ø¶ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø­Ù„ÙˆÙ„ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ¯Ø§Ø®Ù„\n",
        "        colWidths=[1.3 * inch, 0.9 * inch, 1.0 * inch, 3.3 * inch],\n",
        "        hAlign='LEFT',\n",
        "    )\n",
        "\n",
        "    # ğŸ’¡ Ø¥Ø¶Ø§ÙØ© BLANKLINE Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø±Ø£Ø³ÙŠØ© ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„\n",
        "    tbl.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\", (0, 0), (-1, 0), colors.HexColor(\"#F0F0F0\")),\n",
        "        (\"GRID\", (0, 0), (-1, -1), 0.4, colors.grey),\n",
        "        (\"FONTNAME\", (0, 0), (-1, 0), \"Helvetica-Bold\"),\n",
        "        (\"VALIGN\", (0, 0), (-1, -1), \"MIDDLE\"), # ØªØºÙŠÙŠØ± Ø¥Ù„Ù‰ MIDDLE\n",
        "        (\"FONTSIZE\", (0, 0), (-1, 0), 10),\n",
        "        (\"LEFTPADDING\", (0, 0), (-1, -1), 4),\n",
        "        (\"RIGHTPADDING\", (0, 0), (-1, -1), 4),\n",
        "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø³Ø§ÙØ©\n",
        "        ('TOPPADDING', (0, 0), (-1, -1), 6),     # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø³Ø§ÙØ©\n",
        "        ('LINEBELOW', (0,0), (-1,0), 1, colors.black),\n",
        "    ]))\n",
        "\n",
        "    story.append(tbl)\n",
        "    story.append(Spacer(1, 14))\n",
        "    story.append(PageBreak())\n",
        "\n",
        "    # â–‘â–‘â–‘ DETAILED FINDINGS (Wrapped paragraphs everywhere) â–‘â–‘â–‘\n",
        "    story.append(Paragraph(\"Detailed Findings\", H2))\n",
        "    story.append(Spacer(1, 8))\n",
        "\n",
        "    for i, (_, r) in enumerate(df.iterrows(), start=1):\n",
        "        story.append(Paragraph(f\"{i}. {r.get('cve_id', 'UNKNOWN')}\", styles[\"Heading3\"]))\n",
        "\n",
        "        story.append(Paragraph(f\"<b>Title:</b> {r.get('title', 'â€”')}\", Wrapped))\n",
        "        story.append(Paragraph(\n",
        "            f\"<b>Priority:</b> {r.get('priority', 'Unknown')} &nbsp;&nbsp; \"\n",
        "            f\"<b>Effort:</b> {r.get('effort', 'Unknown')} &nbsp;&nbsp; \"\n",
        "            f\"<b>CVSS:</b> {r.get('cvss_v3', 'â€”')}\",\n",
        "            Wrapped,\n",
        "        ))\n",
        "\n",
        "        # Description (wrapped)\n",
        "        desc = r.get(\"description\", \"â€”\") or \"â€”\"\n",
        "        story.append(Paragraph(f\"<b>Description:</b><br/>{desc}\", Wrapped))\n",
        "\n",
        "        # âœ” SAFE MITIGATION LIST\n",
        "        mit_raw = r.get(\"mitigations\", \"\") or \"\"\n",
        "        mit_list = (\n",
        "            [x.strip() for x in mit_raw.split(\",\") if x.strip()]\n",
        "            if mit_raw.lower() not in [\"none\", \"nan\"] and mit_raw\n",
        "            else []\n",
        "        )\n",
        "\n",
        "        if mit_list:\n",
        "            story.append(Paragraph(\"<b>Mitigations:</b>\", Normal))\n",
        "            story.append(ListFlowable(\n",
        "                [ListItem(Paragraph(x, Wrapped)) for x in mit_list[:8]],\n",
        "                bulletType=\"bullet\",\n",
        "                start=\"circle\",\n",
        "            ))\n",
        "\n",
        "        # âœ” SAFE REFERENCES\n",
        "        ref_raw = r.get(\"references\", \"\") or \"\"\n",
        "        ref_list = [x.strip() for x in ref_raw.split(\",\") if x.strip()]\n",
        "\n",
        "        if ref_list:\n",
        "            story.append(Paragraph(\"<b>References:</b>\", Normal))\n",
        "            story.append(ListFlowable(\n",
        "                [ListItem(Paragraph(x, Wrapped)) for x in ref_list[:8]],\n",
        "                bulletType=\"bullet\",\n",
        "            ))\n",
        "\n",
        "        story.append(Spacer(1, 12))\n",
        "\n",
        "    # Build PDF\n",
        "    doc.build(story)\n",
        "    buf.seek(0)\n",
        "\n",
        "    prio_suffix = f\"_{filter_prio}\" if filter_prio and filter_prio != \"All\" else \"\"\n",
        "    filename = f\"CyberMind_Report{prio_suffix}_{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.pdf\"\n",
        "    return buf, filename\n",
        "\n",
        "\n",
        "def simple_qa(df, question):\n",
        "    \"\"\"Tiny lexical Q&A over the loaded data.\"\"\"\n",
        "    q = question.lower().strip()\n",
        "    if not len(df): return \"No data loaded yet.\"\n",
        "    scored = []\n",
        "    for _, r in df.iterrows():\n",
        "        text = f\"{r.get('title','')} {r.get('description','')}\".lower()\n",
        "        score = sum(1 for token in q.split() if token in text)\n",
        "        if score > 0:\n",
        "            scored.append((score, r))\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    top = [r for _, r in scored[:3]] if scored else []\n",
        "    lines = [\"Hereâ€™s what I found:\"]\n",
        "    for r in top:\n",
        "        lines.append(f\"- {r.get('cve_id','?')} â€” {r.get('priority','Unknown')}: {(r.get('title') or r.get('description',''))[:80]}...\")\n",
        "    if not top:\n",
        "        lines.append(\"- No exact matches. Try another keyword.\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ OpenAI enrichment â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "def _get_openai_client():\n",
        "    \"\"\"\n",
        "    Returns an authenticated OpenAI client using either Streamlit secrets or environment variables.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import streamlit as st\n",
        "    from openai import OpenAI\n",
        "\n",
        "    try:\n",
        "        key = st.secrets[\"OPENAI_API_KEY\"]\n",
        "    except Exception:\n",
        "        key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "    if not key:\n",
        "        st.error(\"âš ï¸ No OpenAI API key found. Please set it using os.environ or add secrets.toml file.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        client = OpenAI(api_key=key)\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        st.error(f\"âŒ Failed to initialize OpenAI client: {e}\")\n",
        "        return None\n",
        "\n",
        "AI_SYSTEM = (\n",
        "    \"You are a cybersecurity assistant. Given a vulnerability text, \"\n",
        "    \"return a SHORT, ACTIONABLE, JSON object with keys: \"\n",
        "    \"priority (Critical/High/Medium/Low/Unknown), \"\n",
        "    \"category (SQL Injection, XSS, RCE, Auth, Misconfiguration, DoS, InfoLeak, Other), \"\n",
        "    \"summary, mitigations (array), estimated_effort (Low/Medium/High), references (array).\"\\\n",
        "    \"Focus on providing strong, specific mitigation steps.\"\n",
        ")\n",
        "\n",
        "def _ai_classify(client, title: str, desc: str) -> dict:\n",
        "    if not client: return {}\n",
        "    prompt = (\n",
        "        \"TEXT:\\n\\\"\\\"\\\"\\n\" + (title or \"\") + \"\\n\" + (desc or \"\") + \"\\n\\\"\\\"\\\"\\n\\n\"\n",
        "        \"Return ONLY valid JSON with keys: priority, category, summary, mitigations, \"\n",
        "        \"estimated_effort, references.\"\n",
        "    )\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=OPENAI_MODEL,\n",
        "            temperature=0.2,\n",
        "            response_format={\"type\":\"json_object\"},\n",
        "            messages=[{\"role\":\"system\",\"content\":AI_SYSTEM},\n",
        "                      {\"role\":\"user\",\"content\":prompt}],\n",
        "        )\n",
        "        return json.loads(resp.choices[0].message.content)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "# ğŸ’¡ ØªØ¹Ø²ÙŠØ² Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø«Ø±Ø§Ø¡\n",
        "def enrich_df_with_ai(df: pd.DataFrame, batch_size: int = 100) -> pd.DataFrame:\n",
        "    \"\"\"Enforce AI/Hardcoded Mitigation for Critical/High, and enrich missing fields.\"\"\"\n",
        "    client = _get_openai_client()\n",
        "    if client is None or df.empty:\n",
        "        return df\n",
        "\n",
        "    # ğŸ’¡ ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚ AI Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ø¥Ù…Ø§:\n",
        "    # 1. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø£Ùˆ Ø§Ù„ÙˆØµÙ Ø£Ùˆ Ø§Ù„Ø­Ù„ÙˆÙ„ (ÙØ§Ø±ØºØ©/Ù…Ø¬Ù‡ÙˆÙ„Ø©).\n",
        "    # 2. Ù‡ÙŠ Critical Ø£Ùˆ High ÙˆÙ„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­Ù„ÙˆÙ„.\n",
        "    # 3. ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø­Ù„ÙˆÙ„ ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ØªÙƒØ±Ø§Ø± Ø¹Ù†Ø¯ Ø§Ù„Ø¯Ù…Ø¬.\n",
        "\n",
        "    # ğŸ’¡ Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„ØµÙ„Ø¨Ø© (Hardcoded rules) Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ Ø¯Ø§Ù„Ø© normalize_records.\n",
        "    # Ù‡Ù†Ø§ Ù†Ø±ÙƒØ² Ø¹Ù„Ù‰ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ ÙØ´Ù„Øª ÙÙŠÙ‡Ø§ Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯.\n",
        "\n",
        "    # â¬…ï¸ Ø§Ù„Ø´Ø±Ø· Ù„ÙØ±Ø¶ Ø§Ù„Ø¥Ø«Ø±Ø§Ø¡ Ø¹Ø¨Ø± AI\n",
        "    needs_ai_enrichment = (\n",
        "        # 1. Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø© Ø£Ùˆ Ø§Ù„Ø­Ù„ÙˆÙ„ ÙØ§Ø±ØºØ© (Ø¨Ø§Ù„Ø±ØºÙ… Ù…Ù† ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØµÙ„Ø¨Ø©)\n",
        "        df[\"priority\"].fillna(\"\").eq(\"Unknown\") |\n",
        "        df[\"mitigations\"].fillna(\"\").eq(\"\") |\n",
        "        # 2. Ù‡ÙŠ Critical Ø£Ùˆ High Ù„ÙƒÙ†Ù‡Ø§ ØªÙØªÙ‚Ø± Ø¥Ù„Ù‰ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø£Ùˆ Ø§Ù„ÙˆØµÙ (Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©)\n",
        "        (df[\"priority\"].isin([\"Critical\", \"High\"]) & (df[\"mitigations\"].fillna(\"\").eq(\"\") | df[\"description\"].fillna(\"\").eq(\"\")))\n",
        "    )\n",
        "\n",
        "    idxs = df[needs_ai_enrichment].head(batch_size).index.tolist()\n",
        "    if not idxs: return df\n",
        "\n",
        "    st.info(f\"AI enriching {len(idxs)} high-value or missing records...\")\n",
        "\n",
        "    for rid in idxs:\n",
        "        r = df.loc[rid].to_dict()\n",
        "        ai = _ai_classify(client, r.get(\"title\",\"\"), r.get(\"description\",\"\"))\n",
        "        if isinstance(ai, dict) and ai:\n",
        "\n",
        "            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©\n",
        "            if r.get(\"priority\") in (None, \"\", \"Unknown\"):\n",
        "                df.at[rid, \"priority\"] = ai.get(\"priority\",\"Unknown\")\n",
        "\n",
        "            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆØµÙ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙØ§Ø±ØºØ§Ù‹\n",
        "            if not r.get(\"description\"):\n",
        "                df.at[rid, \"description\"] = ai.get(\"summary\",\"\")\n",
        "\n",
        "            # Ø¯Ù…Ø¬ Ø§Ù„Ø­Ù„ÙˆÙ„ (AI Solutions always take priority if critical/high)\n",
        "            mits_ai = ai.get(\"mitigations\") or []\n",
        "            base_mits = [x.strip() for x in str(r.get(\"mitigations\", \"\")).split(\",\") if x.strip()]\n",
        "\n",
        "            if mits_ai:\n",
        "                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Critical Ø£Ùˆ HighØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø­Ù„ÙˆÙ„ AI ÙƒØ£ÙˆÙ„ÙˆÙŠØ© Ù‚ØµÙˆÙ‰ ÙˆÙ†Ø¶ÙŠÙÙ‡Ø§ Ù„Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©\n",
        "                if df.at[rid, \"priority\"] in (\"Critical\", \"High\"):\n",
        "                    merged = list(dict.fromkeys([str(x).strip() for x in mits_ai if str(x).strip()] + base_mits))\n",
        "                # ÙˆØ¥Ù„Ø§ Ù†Ø¯Ù…Ø¬Ù‡Ø§ Ù…Ø¹ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©\n",
        "                else:\n",
        "                    merged = list(dict.fromkeys(base_mits + [str(x).strip() for x in mits_ai if str(x).strip()]))\n",
        "\n",
        "                df.at[rid, \"mitigations\"] = \", \".join(merged)\n",
        "\n",
        "            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù‡Ø¯\n",
        "            if r.get(\"effort\") in (None, \"\", \"Unknown\"):\n",
        "                df.at[rid, \"effort\"] = (ai.get(\"estimated_effort\",\"Unknown\") or \"Unknown\").title()\n",
        "\n",
        "            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹\n",
        "            refs_ai = ai.get(\"references\") or []\n",
        "            if refs_ai:\n",
        "                base = [x.strip() for x in str(r.get(\"references\", \"\")).split(\",\") if x.strip()]\n",
        "                merged = list(dict.fromkeys(base + [str(x).strip() for x in refs_ai if str(x).strip()]))\n",
        "                df.at[rid, \"references\"] = \", \".join(merged)\n",
        "\n",
        "    return df\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Sidebar (input & filters) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "st.sidebar.title(\"ğŸ›  Controls\")\n",
        "uploaded = st.sidebar.file_uploader(\"Upload CyberMind data (JSON / CSV)\", type=[\"json\",\"csv\"])\n",
        "st.sidebar.markdown('<span class=\"cm-sub\">If empty, demo data will be used.</span>', unsafe_allow_html=True)\n",
        "\n",
        "raw = load_any_file(uploaded) if uploaded else DEMO_DATA\n",
        "df = normalize_records(raw)\n",
        "\n",
        "# â¬…ï¸â¬…ï¸ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¥Ø«Ø±Ø§Ø¡ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ\n",
        "if len(df) and uploaded is not None:\n",
        "    with st.spinner(\"AI enrichment in progress (auto)â€¦\"):\n",
        "        df = enrich_df_with_ai(df, batch_size=100)\n",
        "    st.sidebar.success(\"AI enrichment complete!\")\n",
        "\n",
        "st.sidebar.divider()\n",
        "query = st.sidebar.text_input(\"Search in CVE / title / description\", \"\")\n",
        "severities = st.sidebar.multiselect(\"Filter by Priority\", [\"All\",\"Critical\",\"High\",\"Medium\",\"Low\",\"Unknown\"], default=[\"All\"])\n",
        "\n",
        "def apply_filters(df, query, severities):\n",
        "    return filter_dataframe(df, query, severities or [\"All\"])\n",
        "\n",
        "filtered = apply_filters(df, query, severities)\n",
        "\n",
        "st.sidebar.divider()\n",
        "st.sidebar.subheader(\"ğŸ’¬ Ask CyberMind\")\n",
        "user_q = st.sidebar.text_input(\"Ask (e.g., 'highest risk SQL')\", \"\")\n",
        "if user_q:\n",
        "    st.sidebar.info(simple_qa(filtered, user_q))\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "colA, colB = st.columns([0.7,0.3])\n",
        "with colA:\n",
        "    st.markdown('<div class=\"cm-h1\">CyberMind Dashboard</div>', unsafe_allow_html=True)\n",
        "    st.markdown('<div class=\"cm-sub\">AI-Powered Multi-Agent Cybersecurity Intelligence Framework</div>', unsafe_allow_html=True)\n",
        "with colB:\n",
        "    st.markdown(f'<span class=\"cm-badge\">Live Prototype</span>', unsafe_allow_html=True)\n",
        "    st.caption(f\"Records loaded: {len(df)}  |  Filtered: {len(filtered)}\")\n",
        "st.divider()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ KPIs â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "c1, c2, c3, c4, c5 = st.columns(5)\n",
        "\n",
        "with c1: kpi_card(\"Total Findings\", len(filtered))\n",
        "with c2: kpi_card(\"Critical Priority\", int((filtered[\"priority\"]==\"Critical\").sum()) if \"priority\" in filtered else 0)\n",
        "with c3: kpi_card(\"High Priority\", int((filtered[\"priority\"]==\"High\").sum()) if \"priority\" in filtered else 0)\n",
        "with c4: kpi_card(\"With Mitigations\", int(filtered[\"mitigations\"].astype(bool).sum()))\n",
        "with c5: kpi_card(\"Unique Sources\", filtered[\"source\"].nunique() if \"source\" in filtered else 1)\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "t1, t2, t3, t4, t5 = st.tabs([\"Overview\",\"Threats\",\"Vulnerabilities\",\"Mitigations\",\"Report\"])\n",
        "\n",
        "with t1:\n",
        "    st.subheader(\"Overview\")\n",
        "    if len(filtered):\n",
        "        dist = filtered[\"priority\"].fillna(\"Unknown\").value_counts()\n",
        "        fig, ax = plt.subplots()\n",
        "        dist.plot(kind=\"bar\", ax=ax)\n",
        "        ax.set_title(\"Priority Distribution\"); ax.set_xlabel(\"Priority\"); ax.set_ylabel(\"Count\")\n",
        "        st.pyplot(fig)\n",
        "    st.dataframe(filtered[[\"cve_id\",\"title\",\"priority\",\"cvss_v3\",\"source\"]], use_container_width=True, height=360)\n",
        "\n",
        "with t2:\n",
        "    st.subheader(\"Threats (Raw)\")\n",
        "    st.dataframe(filtered[[\"cve_id\",\"title\",\"description\",\"source\"]], use_container_width=True, height=480)\n",
        "\n",
        "with t3:\n",
        "    st.subheader(\"Vulnerabilities\")\n",
        "    left, right = st.columns([0.55, 0.45])\n",
        "    with left:\n",
        "        st.markdown(\"Top items by CVSS (approx)\")\n",
        "        st.dataframe(\n",
        "            filtered.sort_values(\"cvss_numeric\", ascending=False)[[\"cve_id\",\"title\",\"cvss_v3\",\"priority\"]].head(15),\n",
        "            use_container_width=True, height=380\n",
        "        )\n",
        "    with right:\n",
        "        st.markdown(\"CVSS (approx) Histogram\")\n",
        "        if filtered[\"cvss_numeric\"].notna().any():\n",
        "            fig2, ax2 = plt.subplots()\n",
        "            filtered[\"cvss_numeric\"].dropna().plot(kind=\"hist\", bins=8, ax=ax2)\n",
        "            ax2.set_xlabel(\"CVSS (approx)\")\n",
        "            st.pyplot(fig2)\n",
        "        else:\n",
        "            st.info(\"No numeric CVSS parsed from the dataset.\")\n",
        "\n",
        "with t4:\n",
        "    st.subheader(\"Mitigations\")\n",
        "    # Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­Ù„ÙˆÙ„ (Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¥Ø«Ø±Ø§Ø¡)\n",
        "    st.dataframe(filtered[filtered[\"mitigations\"].astype(bool)][[\"cve_id\",\"priority\",\"mitigations\",\"references\"]], use_container_width=True, height=480)\n",
        "\n",
        "with t5:\n",
        "    st.subheader(\"Generate Report\")\n",
        "\n",
        "    # â¬…ï¸â¬…ï¸ Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø± Ø§Ù„ÙÙ„ØªØ±Ø© Ù„ØªÙ‚Ø±ÙŠØ± PDF\n",
        "    report_priority = st.selectbox(\n",
        "        \"Filter Report by Priority:\",\n",
        "        options=[\"All\", \"Critical\", \"High\", \"Medium\", \"Low\", \"Unknown\"],\n",
        "        index=0,\n",
        "        key=\"pdf_prio_filter\"\n",
        "    )\n",
        "\n",
        "    col_pdf, col_json, col_csv = st.columns(3)\n",
        "\n",
        "    with col_pdf:\n",
        "        if st.button(f\" Generate PDF ({report_priority} Only)\", key=\"pdf_gen\"):\n",
        "            # ğŸ’¡ ØªÙ…Ø±ÙŠØ± Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„Ø¯Ø§Ù„Ø©\n",
        "            pdf_bytes, fname = make_pdf(df, filter_prio=report_priority)\n",
        "\n",
        "            if pdf_bytes is None:\n",
        "                st.error(\"Could not generate PDF. Check filters or data.\")\n",
        "            else:\n",
        "                st.success(\"PDF generated successfully!\")\n",
        "\n",
        "                # ---- (A) DOWNLOAD TO USER'S LOCAL DEVICE ----\n",
        "                st.download_button(\n",
        "                    label=\" Download PDF\",\n",
        "                    data=pdf_bytes,\n",
        "                    file_name=fname,\n",
        "                    mime=\"application/pdf\",\n",
        "                    key=\"pdf_dl\",\n",
        "                )\n",
        "\n",
        "                # ---- (B) SAVE ON SERVER (optional) ----\n",
        "                import os\n",
        "                save_folder = \"saved_reports\"\n",
        "                os.makedirs(save_folder, exist_ok=True)\n",
        "                local_path = os.path.join(save_folder, fname)\n",
        "\n",
        "                with open(local_path, \"wb\") as f:\n",
        "                    f.write(pdf_bytes.getbuffer())\n",
        "\n",
        "                st.info(f\"PDF also saved on server at: {local_path}\")\n",
        "\n",
        "st.caption(\"Â© CyberMind â€” SDA Generative AI / LLM Bootcamp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy7Fnk70ZlBx",
        "outputId": "28be0f88-7bf6-4c06-fd1f-656455462b9b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C: install cloudflared (deb)\n",
        "!wget -q -O cloudflared.deb \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\"\n",
        "!sudo dpkg -i cloudflared.deb || true\n",
        "# if dpkg reports dependencies, try apt-get -f install\n",
        "!sudo apt-get -y -f install\n",
        "!cloudflared --version || echo \"cloudflared not found\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCSnsfIBljx9",
        "outputId": "24d0618a-a0e0-4fc4-8141-9c74eb9f8dd7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 121707 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared.deb ...\n",
            "Unpacking cloudflared (2025.11.1) over (2025.11.1) ...\n",
            "Setting up cloudflared (2025.11.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "cloudflared version 2025.11.1 (built 2025-11-07-16:59 UTC)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D: start Streamlit in background\n",
        "import subprocess, time, os, signal, pathlib\n",
        "\n",
        "# kill any existing streamlit processes\n",
        "!pkill -f streamlit || true\n",
        "\n",
        "# start streamlit and send logs to file\n",
        "log_stream = \"streamlit.log\"\n",
        "cmd = [\"streamlit\",\"run\",\"app.py\",\"--server.port\",\"8501\",\"--server.enableCORS\",\"false\",\"--server.enableXsrfProtection\",\"false\"]\n",
        "p = subprocess.Popen(cmd, stdout=open(log_stream,\"w\"), stderr=subprocess.STDOUT, text=True)\n",
        "time.sleep(4)\n",
        "print(\"Started Streamlit (pid {}). Logs -> {}\".format(p.pid, log_stream))\n",
        "print(\"Local URL: http://localhost:8501\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmNaSFOflulI",
        "outputId": "6f46e0dd-1696-41f9-ce5d-ee0f9afa7767"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "Started Streamlit (pid 20242). Logs -> streamlit.log\n",
            "Local URL: http://localhost:8501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell E: start cloudflared tunnel and extract public URL\n",
        "import subprocess, time, pathlib, re\n",
        "\n",
        "# kill any previous cloudflared\n",
        "!pkill -f cloudflared || true\n",
        "\n",
        "log_path = \"cloudflared.log\"\n",
        "# Start cloudflared (non-blocking)\n",
        "proc = subprocess.Popen([\"cloudflared\",\"tunnel\",\"--url\",\"http://localhost:8501\",\"--no-autoupdate\",\"--logfile\",log_path,\"--loglevel\",\"info\"],\n",
        "                        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "# wait and poll the logfile for the public URL\n",
        "public_url = None\n",
        "for i in range(45):  # up to ~45 seconds\n",
        "    time.sleep(1)\n",
        "    if pathlib.Path(log_path).exists():\n",
        "        txt = pathlib.Path(log_path).read_text(errors=\"ignore\")\n",
        "        m = re.search(r\"https://[-a-z0-9]+\\.trycloudflare\\.com\", txt)\n",
        "        if m:\n",
        "            public_url = m.group(0)\n",
        "            break\n",
        "\n",
        "if public_url:\n",
        "    print(\"âœ… Public URL:\", public_url)\n",
        "else:\n",
        "    print(\"âš ï¸ Couldn't find public URL in cloudflared.log yet.\")\n",
        "    print(\"Last 40 lines from the log:\")\n",
        "    if pathlib.Path(log_path).exists():\n",
        "        print(\"\\n\".join(pathlib.Path(log_path).read_text().splitlines()[-40:]))\n",
        "    else:\n",
        "        print(\"cloudflared.log not found. Check cloudflared installation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq7q8ew9l8Z8",
        "outputId": "0bb3a16f-1e8a-454c-c990-1aef4cb5a376"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "âœ… Public URL: https://mounts-cognitive-vocabulary-impossible.trycloudflare.com\n"
          ]
        }
      ]
    }
  ]
}